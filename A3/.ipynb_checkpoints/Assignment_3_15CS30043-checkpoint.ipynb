{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse import DependencyGraph, DependencyEvaluator\n",
    "from nltk.parse.transitionparser import TransitionParser, Configuration, Transition\n",
    "import tempfile\n",
    "import os\n",
    "from numpy import array\n",
    "from scipy import sparse\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import neural_network\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hi-ud-train.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d08bded586b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDependencyGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi-ud-train.conllu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/nltk/parse/dependencygraph.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             return [\n\u001b[1;32m    239\u001b[0m                 DependencyGraph(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hi-ud-train.conllu'"
     ]
    }
   ],
   "source": [
    "f = DependencyGraph.load(\"hi-ud-train.conllu\")\n",
    "conf = Configuration(f[0])\n",
    "print(', '.join(conf.extract_features()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating two files - One with the morphological features and one without the morphological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Data\n",
    "f1 = open('with_morpho_train.conllu',\"w+\")\n",
    "f2 = open('without_morpho_train.conllu',\"w+\")\n",
    "with open(\"hi-ud-train.conllu\",\"r+\",encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if(line == '\\n'):\n",
    "            f1.write(line)\n",
    "            f2.write(line)\n",
    "        else:\n",
    "            line = line.split('\\t')\n",
    "            line1 = list(line)\n",
    "            line1[5] = line1[5]+\"|\"+line1[9][:-1]\n",
    "            line[5] = \"_\"\n",
    "            line = '\\t'.join(line)\n",
    "            line1 = '\\t'.join(line1)\n",
    "            f1.write(line1)\n",
    "            f2.write(line)\n",
    "f1.close()\n",
    "f2.close()\n",
    "\n",
    "#Test Data\n",
    "f1 = open('with_morpho_test.conllu',\"w+\")\n",
    "f2 = open('without_morpho_test.conllu',\"w+\")\n",
    "with open(\"hi-ud-test.conllu\",\"r+\",encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if(line == '\\n'):\n",
    "            f1.write(line)\n",
    "            f2.write(line)\n",
    "        else:\n",
    "            line = line.split('\\t')\n",
    "            line1 = list(line)\n",
    "            line1[5] = line1[5]+\"|\"+line1[9][:-1]\n",
    "            line[5] = \"_\"\n",
    "            line = '\\t'.join(line)\n",
    "            line1 = '\\t'.join(line1)\n",
    "            f1.write(line1)\n",
    "            f2.write(line)\n",
    "f1.close()\n",
    "f2.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transition Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyTransitionParser(TransitionParser):\n",
    "    def train(self, depgraphs, modelfile, classifier=\"svm\",verbose=True):\n",
    "        \"\"\"\n",
    "        :param depgraphs : list of DependencyGraph as the training data\n",
    "        :type depgraphs : DependencyGraph\n",
    "        :param modelfile : file name to save the trained model\n",
    "        :type modelfile : str\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            input_file = tempfile.NamedTemporaryFile(\n",
    "                prefix='transition_parse.train',\n",
    "                dir=tempfile.gettempdir(),\n",
    "                delete=False)\n",
    "\n",
    "            if self._algorithm == self.ARC_STANDARD:\n",
    "                self._create_training_examples_arc_std(depgraphs, input_file)\n",
    "            else:\n",
    "                self._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "            input_file.close()\n",
    "            # Using the temporary file to train the libsvm classifier\n",
    "            x_train, y_train = load_svmlight_file(input_file.name)\n",
    "            # The parameter is set according to the paper:\n",
    "            # Algorithms for Deterministic Incremental Dependency Parsing by Joakim Nivre\n",
    "            # Todo : because of probability = True => very slow due to\n",
    "            # cross-validation. Need to improve the speed here\n",
    "            if(classifier == \"svm\"):\n",
    "                model = svm.SVC(\n",
    "                    kernel='poly',\n",
    "                    degree=2,\n",
    "                    coef0=0,\n",
    "                    gamma=0.2,\n",
    "                    C=0.5,\n",
    "                    verbose=verbose,\n",
    "                    probability=True)\n",
    "            elif(classifier == \"logistic\"):\n",
    "                model = linear_model.LogisticRegression(\n",
    "                    C = 0.5,\n",
    "                    solver = 'lbfgs',\n",
    "                    verbose = verbose)\n",
    "            elif(classifier == \"mlp\"):\n",
    "                model = neural_network.MLPClassifier(\n",
    "                    hidden_layer_sizes=(100,50,),\n",
    "                    learning_rate = 'adaptive',\n",
    "                    max_iter=1000\n",
    "                    )\n",
    "            model.fit(x_train, y_train)\n",
    "            # Save the model to file name (as pickle)\n",
    "            pickle.dump(model, open(modelfile, 'wb'))\n",
    "        finally:\n",
    "            os.remove(input_file.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Morphological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/envs/nlp/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "graph_morpho_train = DependencyGraph.load(\"with_morpho_train.conllu\")\n",
    "graph_morpho_test = DependencyGraph.load(\"with_morpho_test.conllu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.9123204837490552, 0.8306878306878307)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_m_std_svm = MyTransitionParser('arc-standard')\n",
    "parser_m_std_svm.train(graph_morpho_train,'temp.arcstd_m_svm.model',verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_m_std_svm = parser_m_std_svm.parse(graph_morpho_test, 'temp.arcstd_m_svm.model')\n",
    "d1 = DependencyEvaluator(result_m_std_svm, graph_morpho_test)\n",
    "print(d1.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8669690098261527, 0.7671957671957672)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_m_std_log = MyTransitionParser('arc-standard')\n",
    "parser_m_std_log.train(graph_morpho_train,'temp.arcstd_m_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_m_std_log = parser_m_std_log.parse(graph_morpho_test, 'temp.arcstd_m_log.model')\n",
    "d2 = DependencyEvaluator(result_m_std_log, graph_morpho_test)\n",
    "print(d2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8578987150415722, 0.7603930461073318)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_m_std_mlp = MyTransitionParser('arc-standard')\n",
    "parser_m_std_mlp.train(graph_morpho_train,'temp.arcstd_m_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_m_std_mlp = parser_m_std_mlp.parse(graph_morpho_test, 'temp.arcstd_m_mlp.model')\n",
    "d3 = DependencyEvaluator(result_m_std_mlp, graph_morpho_test)\n",
    "print(d3.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Eager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.9123204837490552, 0.8276643990929705)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_m_eag_svm = MyTransitionParser('arc-eager')\n",
    "parser_m_eag_svm.train(graph_morpho_train,'temp.arceag_m_svm.model',verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_m_eag_svm = parser_m_eag_svm.parse(graph_morpho_test, 'temp.arceag_m_svm.model')\n",
    "d4 = DependencyEvaluator(result_m_eag_svm, graph_morpho_test)\n",
    "print(d4.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.9024943310657596, 0.8027210884353742)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_m_eag_log = MyTransitionParser('arc-eager')\n",
    "parser_m_eag_log.train(graph_morpho_train,'temp.arceag_m_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_m_eag_log = parser_m_eag_log.parse(graph_morpho_test, 'temp.arceag_m_log.model')\n",
    "d5 = DependencyEvaluator(result_m_eag_log, graph_morpho_test)\n",
    "print(d5.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8639455782312925, 0.762660619803477)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_m_eag_mlp = MyTransitionParser('arc-eager')\n",
    "parser_m_eag_mlp.train(graph_morpho_train,'temp.arceag_m_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_m_eag_mlp = parser_m_eag_mlp.parse(graph_morpho_test, 'temp.arceag_m_mlp.model')\n",
    "d6 = DependencyEvaluator(result_m_eag_mlp, graph_morpho_test)\n",
    "print(d6.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Morphological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/envs/nlp/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "graph_train = DependencyGraph.load(\"without_morpho_train.conllu\")\n",
    "graph_test = DependencyGraph.load(\"without_morpho_test.conllu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8488284202569917, 0.764928193499622)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_std_svm = MyTransitionParser('arc-standard')\n",
    "parser_std_svm.train(graph_train,'temp.arcstd_svm.model',verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_std_svm = parser_std_svm.parse(graph_test, 'temp.arcstd_svm.model')\n",
    "d7 = DependencyEvaluator(result_std_svm, graph_test)\n",
    "print(d7.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.7928949357520786, 0.6817838246409675)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_std_log = MyTransitionParser('arc-standard')\n",
    "parser_std_log.train(graph_train,'temp.arcstd_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_std_log = parser_std_log.parse(graph_test, 'temp.arcstd_log.model')\n",
    "d8 = DependencyEvaluator(result_std_log, graph_test)\n",
    "print(d8.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.7974300831443688, 0.6870748299319728)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_std_mlp = MyTransitionParser('arc-standard')\n",
    "parser_std_mlp.train(graph_train,'temp.arcstd_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_std_mlp = parser_std_mlp.parse(graph_test, 'temp.arcstd_mlp.model')\n",
    "d9 = DependencyEvaluator(result_std_mlp, graph_test)\n",
    "print(d9.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Eager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.871504157218443, 0.7747543461829176)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_eag_svm = MyTransitionParser('arc-eager')\n",
    "parser_eag_svm.train(graph_train,'temp.arceag_svm.model',verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_eag_svm = parser_eag_svm.parse(graph_test, 'temp.arceag_svm.model')\n",
    "d10 = DependencyEvaluator(result_eag_svm, graph_test)\n",
    "print(d10.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8435374149659864, 0.7278911564625851)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_eag_log = MyTransitionParser('arc-eager')\n",
    "parser_eag_log.train(graph_train,'temp.arceag_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_eag_log = parser_eag_log.parse(graph_test, 'temp.arceag_log.model')\n",
    "d11 = DependencyEvaluator(result_eag_log, graph_test)\n",
    "print(d11.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8155706727135299, 0.6931216931216931)\n"
     ]
    }
   ],
   "source": [
    "#Training the parser\n",
    "parser_eag_mlp = MyTransitionParser('arc-eager')\n",
    "parser_eag_mlp.train(graph_train,'temp.arceag_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing the parser\n",
    "result_eag_mlp = parser_eag_mlp.parse(graph_test, 'temp.arceag_mlp.model')\n",
    "d12 = DependencyEvaluator(result_eag_mlp, graph_test)\n",
    "print(d12.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
