{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "### Speech & NLP\n",
    "\n",
    "### Name : Prerit Gupta, Roll No: 14EC35001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "#### Generative Models\n",
    "\n",
    "(a) Naive’s Bayes Classifier: The NB Classifier is based on the Baye’s theorum : p(y|x) = p(x|y)p(y)/p(x)  = p(x,y)/p(x), but it doesn’t model the conditional probability directly. It models the joint probability, and after that it calculates p(y|x).  This model can be used to generate data on the basis of p(x,y) modelled.\n",
    "\n",
    "(b) Gaussian Mixture Model: It represents the mixture distributions or joint distributions on gaussian distributed assumption of variables. A GMM can be used to generate data from the joint gaussian distribution of variable modelled.\n",
    "\n",
    "(c) GANs (Generative Adversarial Networks) : The generator network of the GAN models the underlying distribution of the supplied real data and becomes profidient in learning the true distribution of the real dataset by fooling the distinguishing power of the discriminator. Hence, GAN is a generative model used to generate distribution of a given dataset.\n",
    " \n",
    "(d) LDA(Latent Dirichlet Allocation): It is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.  \n",
    "\n",
    "#### Discriminative Models\n",
    "(a) Neural Networks: In neural networks, the likelihood and log-likelihood objective functions are both equivalent to the probability distribution p(y|x) as follows: L(θ) = L(θ;X,y) = L(y|X,θ) where the model θ is chosen to make the p(y|x) as high probability as possible. The task objective is classification of input data which is discrimination among possible class outcomes.\n",
    "\n",
    "(b) Logistic Regression: Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logisitic function (cumulative logical distribution). Logistic regression predicts the probability of particular outcomes rather than the outcomes themselves.\n",
    "\n",
    "(c) SVM (Support Vector Machine): Discriminative classifiers model the posterior (i.e. probability of class  given data, Pr(y|x)) directly from the data. SVM is discriminative because it  explicitly learns the class boundary between the two classes.\n",
    "\n",
    "(d) Decision Tree : A decision tree uses a tree-like graph to perform classification. It is discriminative as it distinguishes the class label of sampe conditioned on its underlying feature attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49680\n",
      "12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank,brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0].lower()\n",
    "        tag= elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1\n",
    "\n",
    "print(len(word_dict))\n",
    "print(len(tag_dict))\n",
    "        \n",
    "test_data= brown.tagged_sents(tagset='universal')[-10:]\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the transition, start and emission matrices from the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "\n",
    "state_len = len(tag_dict)\n",
    "word_len = len(word_dict)\n",
    "state = {}\n",
    "state_val = {}\n",
    "i = 0\n",
    "for s in tag_dict.keys():\n",
    "    state[s] = i\n",
    "    state_val[i] = s\n",
    "    i = i+1\n",
    "word = {}\n",
    "i = 0\n",
    "for w in word_dict.keys():\n",
    "    word[w] = i\n",
    "    i = i+1 \n",
    "P = np.zeros((state_len,state_len))\n",
    "S = np.zeros(state_len)\n",
    "O = np.zeros((state_len,word_len))\n",
    "for sent in corpus:\n",
    "    S[state[sent[0][1]]]+=1\n",
    "    for elem in sent:\n",
    "        O[state[elem[1]],word[elem[0].lower()]]+=1\n",
    "    for elem1,elem2 in ngrams(sent,2, pad_left=False,pad_right=False):\n",
    "        P[state[elem1[1]],state[elem2[1]]]+=1\n",
    "        \n",
    "S = [s/S.sum() for s in S]\n",
    "P_sum = np.sum(P,axis=1)\n",
    "for i,p in enumerate(P):\n",
    "    P[i] = p[:]/P_sum[i]\n",
    "    \n",
    "#Laplacian Smoothing in Emission Matrix\n",
    "k = 0.001\n",
    "O_sum = np.sum(O,axis=1)\n",
    "for i,o in enumerate(O):\n",
    "    for j,val in enumerate(o):\n",
    "        O[i,j] = (val+k)/(O_sum[i]+k*word_len) \n",
    "        \n",
    "#Laplacian Smoothing for unknown words\n",
    "O_unk = np.zeros(state_len)\n",
    "for i in range(state_len):\n",
    "    O_unk[i] = k/(O_sum[i]+k*word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_algo(sequence):\n",
    "    M = len(sequence)\n",
    "    \n",
    "    T = np.zeros((state_len,M))\n",
    "    for i in range(state_len):\n",
    "        T[i][0] = S[i]*O[i,word[sequence[0]]]\n",
    "    for j in range(1,M):\n",
    "        for i in range(state_len):\n",
    "            for k in range(state_len):\n",
    "                if (sequence[j] in word.keys()):\n",
    "                    T[i][j] += T[k][j-1]*P[k,i]*O[i,word[sequence[j]]]\n",
    "                else:\n",
    "                    T[i][j] += T[k][j-1]*P[k,i]*O_unk[i]\n",
    "    states = np.zeros(M)\n",
    "    states[-1] = np.argmax(T[:,-1])\n",
    "    probs = np.zeros(state_len)\n",
    "    for j in reversed(range(M-1)):\n",
    "        for i in range(state_len):\n",
    "            if (sequence[j+1] in word.keys()):\n",
    "                probs[i] = T[i,j]*P[i,int(states[j+1])]*O[int(states[j+1]),word[sequence[j+1]]]\n",
    "            else:\n",
    "                probs[i] = T[i,j]*P[i,int(states[j+1])]*O_unk[int(states[j+1])]\n",
    "        states[j] = np.argmax(probs)\n",
    "\n",
    "    return (states,T[int(states[-1])][-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"you can't very well sidle up to people on the street and ask if they want to buy a hot bodhisattva .\"\n",
      "Length 22\n",
      "The sequence PRON,VERB,ADV,ADV,VERB,PRT,ADP,NOUN,ADP,DET,NOUN,CONJ,VERB,ADP,PRON,VERB,PRT,VERB,DET,ADJ,NOUN,. gave the best score of 5.273308041509585e-66\n",
      "True sequence:PRON,VERB,ADV,ADV,VERB,ADP,ADP,NOUN,ADP,DET,NOUN,CONJ,VERB,ADP,PRON,VERB,PRT,VERB,DET,ADJ,NOUN,.\n",
      "Accuracy: 95.455% Time taken 0.044s\n",
      "\n",
      "\n",
      "Sentence: \"additionally , since you're going to be hors de combat pretty soon with sprue , yaws , delhi boil , the granville wilt , liver fluke , bilharziasis , and a host of other complications of the hex you've aroused , you mustn't expect to be lionized socially .\"\n",
      "Length 49\n",
      "The sequence ADV,.,ADP,PRT,VERB,PRT,VERB,X,X,VERB,ADV,ADV,ADP,NOUN,.,X,.,NOUN,NOUN,.,DET,NOUN,VERB,.,NOUN,.,.,X,.,CONJ,DET,NOUN,ADP,ADJ,NOUN,ADP,DET,NOUN,PRT,VERB,.,PRON,VERB,VERB,PRT,VERB,VERB,ADV,. gave the best score of 1.5861544923363735e-172\n",
      "True sequence:ADV,.,ADP,PRT,VERB,PRT,VERB,X,X,X,ADV,ADV,ADP,NOUN,.,NOUN,.,NOUN,NOUN,.,DET,NOUN,NOUN,.,NOUN,NOUN,.,NOUN,.,CONJ,DET,NOUN,ADP,ADJ,NOUN,ADP,DET,NOUN,PRT,VERB,.,PRON,VERB,VERB,PRT,VERB,VERB,ADV,.\n",
      "Accuracy: 89.796% Time taken 0.109s\n",
      "\n",
      "\n",
      "Sentence: \"my advice , if you live long enough to continue your vocation , is that the next time you're attracted by the exotic , pass it up -- it's nothing but a headache .\"\n",
      "Length 34\n",
      "The sequence DET,NOUN,.,ADP,PRON,VERB,ADV,ADV,PRT,VERB,DET,NOUN,.,VERB,ADP,DET,ADJ,NOUN,PRT,VERB,ADP,DET,ADJ,.,VERB,PRON,PRT,.,PRT,NOUN,CONJ,DET,NOUN,. gave the best score of 8.262976662540573e-95\n",
      "True sequence:DET,NOUN,.,ADP,PRON,VERB,ADJ,ADV,PRT,VERB,DET,NOUN,.,VERB,ADP,DET,ADJ,NOUN,PRT,VERB,ADP,DET,ADJ,.,VERB,PRON,PRT,.,PRT,NOUN,CONJ,DET,NOUN,.\n",
      "Accuracy: 97.059% Time taken 0.073s\n",
      "\n",
      "\n",
      "Sentence: \"as you can count on me to do the same .\"\n",
      "Length 11\n",
      "The sequence ADP,PRON,VERB,VERB,ADP,PRON,PRT,VERB,DET,ADJ,. gave the best score of 2.8146068438540423e-26\n",
      "True sequence:ADP,PRON,VERB,VERB,ADP,PRON,PRT,VERB,DET,ADJ,.\n",
      "Accuracy: 100.0% Time taken 0.019s\n",
      "\n",
      "\n",
      "Sentence: \"compassionately yours ,\"\n",
      "Length 3\n",
      "The sequence ADV,PRON,. gave the best score of 1.5727682021684337e-12\n",
      "True sequence:ADV,PRON,.\n",
      "Accuracy: 100.0% Time taken 0.003s\n",
      "\n",
      "\n",
      "Sentence: \"s. j. perelman\"\n",
      "Length 3\n",
      "The sequence NOUN,NOUN,. gave the best score of 7.734507495038384e-18\n",
      "True sequence:NOUN,NOUN,NOUN\n",
      "Accuracy: 66.667% Time taken 0.003s\n",
      "\n",
      "\n",
      "Sentence: \"revulsion in the desert\"\n",
      "Length 4\n",
      "The sequence NOUN,ADP,DET,NOUN gave the best score of 1.473867848123746e-12\n",
      "True sequence:NOUN,ADP,DET,NOUN\n",
      "Accuracy: 100.0% Time taken 0.004s\n",
      "\n",
      "\n",
      "Sentence: \"the doors of the d train slid shut , and as i dropped into a seat and , exhaling , looked up across the aisle , the whole aviary in my head burst into song .\"\n",
      "Length 36\n",
      "The sequence DET,NOUN,ADP,DET,NOUN,NOUN,VERB,VERB,.,CONJ,ADP,PRON,VERB,ADP,DET,NOUN,CONJ,.,X,.,VERB,PRT,ADP,DET,NOUN,.,DET,ADJ,NOUN,ADP,DET,NOUN,VERB,ADP,NOUN,. gave the best score of 4.280973325500497e-104\n",
      "True sequence:DET,NOUN,ADP,DET,NOUN,NOUN,VERB,VERB,.,CONJ,ADP,PRON,VERB,ADP,DET,NOUN,CONJ,.,VERB,.,VERB,PRT,ADP,DET,NOUN,.,DET,ADJ,NOUN,ADP,DET,NOUN,VERB,ADP,NOUN,.\n",
      "Accuracy: 97.222% Time taken 0.055s\n",
      "\n",
      "\n",
      "Sentence: \"she was a living doll and no mistake -- the blue-black bang , the wide cheekbones , olive-flushed , that betrayed the cherokee strain in her midwestern lineage , and the mouth whose only fault , in the novelist's carping phrase , was that the lower lip was a trifle too voluptuous .\"\n",
      "Length 53\n",
      "The sequence PRON,VERB,DET,NOUN,NOUN,CONJ,DET,NOUN,.,DET,ADJ,NOUN,.,DET,ADJ,NOUN,.,X,.,PRON,VERB,DET,ADJ,NOUN,ADP,DET,ADJ,NOUN,.,CONJ,DET,NOUN,DET,ADJ,NOUN,.,ADP,DET,NOUN,VERB,NOUN,.,VERB,ADP,DET,ADJ,NOUN,VERB,DET,NOUN,ADV,ADJ,. gave the best score of 7.0832748054837024e-161\n",
      "True sequence:PRON,VERB,DET,VERB,NOUN,CONJ,DET,NOUN,.,DET,ADJ,NOUN,.,DET,ADJ,NOUN,.,ADJ,.,PRON,VERB,DET,NOUN,NOUN,ADP,DET,ADJ,NOUN,.,CONJ,DET,NOUN,DET,ADJ,NOUN,.,ADP,DET,NOUN,VERB,NOUN,.,VERB,ADP,DET,ADJ,NOUN,VERB,DET,NOUN,ADV,ADJ,.\n",
      "Accuracy: 94.34% Time taken 0.121s\n",
      "\n",
      "\n",
      "Sentence: \"from what i was able to gauge in a swift , greedy glance , the figure inside the coral-colored boucle dress was stupefying .\"\n",
      "Length 24\n",
      "The sequence ADP,DET,PRON,VERB,ADJ,ADP,NOUN,ADP,DET,NOUN,.,ADJ,NOUN,.,DET,NOUN,ADP,DET,X,X,NOUN,VERB,ADV,. gave the best score of 8.242535560208954e-80\n",
      "True sequence:ADP,DET,PRON,VERB,ADJ,ADP,NOUN,ADP,DET,ADJ,.,ADJ,NOUN,.,DET,NOUN,ADP,DET,ADJ,NOUN,NOUN,VERB,VERB,.\n",
      "Accuracy: 83.333% Time taken 0.037s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequences = [[ele[0].lower() for ele in sent] for sent in test_data]\n",
    "labels = [[ele[1] for ele in sent] for sent in test_data]\n",
    "import time\n",
    "t_acc = 0\n",
    "t_len = 0\n",
    "for i,sequence in enumerate(sequences):\n",
    "    \n",
    "    t=time.time()\n",
    "    best=viterbi_algo(sequence)\n",
    "    t2=time.time()-t\n",
    "    acc=0\n",
    "    for j,k in enumerate(best[0]):\n",
    "        if(state_val[int(k)]==labels[i][j]):\n",
    "            acc+=1\n",
    "    t_acc += acc\n",
    "    t_len +=len(sequence)\n",
    "    acc/=len(sequence)\n",
    "    print('Sentence: \"'+' '.join(s for s in sequence)+ '\"')\n",
    "    print ('Length '+ str(len(sequence)))\n",
    "    print('The sequence '+ ','.join([state_val[int(k)] for k in best[0]])+ ' gave the best score of '+ str(best[1]))\n",
    "    print ('True sequence:'+','.join(l for l in labels[i]))\n",
    "    print ('Accuracy: '+str(round(acc*100,3))+'%'+' Time taken '+ str(round(t2,3))+'s' )   \n",
    "    print('\\n')\n",
    "t_acc /=t_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting overall accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of HMM model is 93.305%\n"
     ]
    }
   ],
   "source": [
    "print (\"Overall accuracy of HMM model is \"+str(round(t_acc*100,3))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 : CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features included for CRF:\n",
    "(a) Lower Case word (previous,current,next): The lower case form of the word can be used to capture semantics where     same words having phrasal relationship is occuring important for semantics of POS tags.\n",
    "\n",
    "(b) Binary feature for Title (previous,current,next): Some words have starting letter capital. This can be used to     distinguish nouns like names of places, people, etc and starting of sentence from other POS tags.\n",
    "\n",
    "(c) Suffix (current):\n",
    "\n",
    "    (i) 3 characters ending : Marking gerund form of word specifically end with 'ing', also modelling specific           suffixes like 'ant','ist','ive'\n",
    "    \n",
    "    (ii) 2 characters ending : Marking plural form of words ending with 'es', also modelling specific suffixes like       'ty','er','al'\n",
    "    \n",
    "(d) POS Tags (previous,current,next) : The POS Tags directly model the labels which is are task on the test             sentences.\n",
    "\n",
    "    \n",
    "Including the above features is leading to 100% accuracy on the test sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "train_sents= corpus\n",
    "\n",
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features ={\n",
    "    'bias': 1.0,\n",
    "    'word.lower()': word.lower(),\n",
    "    'word[-3:]' : word[-3:],\n",
    "    'word[-2:]' : word[-2:],\n",
    "    'word.istitle()': word.istitle(),\n",
    "    'postag' : postag\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:postag': postag1,\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_data]\n",
    "y_test=[sent2labels(s) for s in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prerit/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/prerit/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      1.000     1.000     1.000        33\n",
      "          X      1.000     1.000     1.000         3\n",
      "        ADJ      1.000     1.000     1.000        18\n",
      "        ADP      1.000     1.000     1.000        27\n",
      "        ADV      1.000     1.000     1.000         9\n",
      "       VERB      1.000     1.000     1.000        35\n",
      "        DET      1.000     1.000     1.000        33\n",
      "       CONJ      1.000     1.000     1.000         7\n",
      "       NOUN      1.000     1.000     1.000        51\n",
      "       PRON      1.000     1.000     1.000        12\n",
      "        PRT      1.000     1.000     1.000        11\n",
      "        NUM      0.000     0.000     0.000         0\n",
      "\n",
      "avg / total      1.000     1.000     1.000       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prerit/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/prerit/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
